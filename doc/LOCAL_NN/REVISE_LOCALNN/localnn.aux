\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{Definitions/mdpi}
\citation{nn1,nn2}
\citation{nnphysics1,nnphysics2,nnphysics3}
\citation{nnchem1,nnchem2,nnchem3}
\citation{nnecon1,nnecon2,nncecon3}
\citation{nnmed1,nnmed2}
\citation{nn_flood}
\citation{nn_solar}
\citation{nn_agro}
\citation{nn_wireless}
\citation{nn_mech1}
\citation{nnc}
\newmarginnote{note.1.1}{{1}{10945661sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{eq:eq1}{{1}{1}{Introduction}{equation.1.1}{}}
\newlabel{eq:eq1@cref}{{[equation][1][]1}{[1][1][]1}}
\newlabel{eq:nn}{{2}{1}{Introduction}{equation.1.2}{}}
\newlabel{eq:nn@cref}{{[equation][2][]2}{[1][1][]1}}
\citation{activation_spline}
\citation{activation_trained}
\citation{activation_review}
\citation{bpnn,bpnn2}
\citation{nn_leve}
\citation{rpropnn,rpropnn3,rpropnn2}
\citation{quasinn,quasinn2}
\citation{psonn,psonn2}
\citation{nn_de}
\citation{nn_survey}
\citation{nnhybrid1}
\citation{nnhybrid2}
\citation{csmethod}
\citation{nninit1}
\citation{weight_init2}
\citation{weight_init3}
\citation{nninitreview}
\citation{nn_gpu1}
\citation{nn_gpu2}
\citation{nn_gpu3}
\citation{nn_gpu_review}
\citation{Holland}
\citation{Stender,Goldberg,Michaelewicz}
\citation{ga_problem1}
\citation{ga_problem2,ga_problem3}
\citation{ga_problem4,ga_problem5}
\newlabel{eq:sig}{{3}{2}{Introduction}{equation.1.3}{}}
\newlabel{eq:sig@cref}{{[equation][3][]3}{[1][2][]2}}
\citation{ga_nn1}
\citation{ga_nn2}
\citation{ga_nn3}
\citation{ga_nn4}
\citation{ga_nn5}
\citation{siman_main}
\citation{siman_problem1}
\citation{siman_problem2}
\citation{siman_problem3}
\citation{ga_sa1}
\citation{ga_sa2}
\citation{ga_sa3}
\citation{ga_sa4}
\citation{ga_sa5}
\newlabel{sec:Materials-and-Methods}{{2}{3}{The proposed method\label {sec:Materials-and-Methods}}{section.2}{}}
\newlabel{sec:Materials-and-Methods@cref}{{[section][2][]2}{[1][3][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}The proposed method}{3}{section.2}\protected@file@percent }
\newlabel{subsec:The-new-Simulated}{{2.1}{3}{The new Simulated Annealing variant \label {subsec:The-new-Simulated}}{subsection.2.1}{}}
\newlabel{subsec:The-new-Simulated@cref}{{[subsection][1][2]2.1}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The new Simulated Annealing variant }{3}{subsection.2.1}\protected@file@percent }
\citation{ga_drug}
\citation{ga_gear}
\citation{ga_forecasting}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:siman}{{1}{4}{The used variant of the Simulated Annealing algorithm.\relax }{algorithm.1}{}}
\newlabel{alg:siman@cref}{{[algorithm][1][]1}{[1][3][]4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces The used variant of the Simulated Annealing algorithm.\relax }}{4}{algorithm.1}\protected@file@percent }
\newlabel{enu:For-}{{6}{4}{The new Simulated Annealing variant \label {subsec:The-new-Simulated}}{Item.6}{}}
\newlabel{enu:For-@cref}{{[enumi][6][]6}{[1][3][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}The overall algorithm}{4}{subsection.2.2}\protected@file@percent }
\citation{kaelo}
\citation{Powell}
\newlabel{enu:Fitness-calculation-Step}{{2b}{5}{The overall algorithm}{Item.30}{}}
\newlabel{enu:Fitness-calculation-Step@cref}{{[enumii][2][2]2b}{[1][5][]5}}
\newlabel{eq:crossover_ali-1}{{5}{5}{The overall algorithm}{equation.2.5}{}}
\newlabel{eq:crossover_ali-1@cref}{{[enumii][2][3]3b}{[1][5][]5}}
\citation{UCL}
\citation{Keel}
\citation{appendicitis}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The overall proposed algorithm.\relax }}{6}{figure.caption.1}\protected@file@percent }
\newlabel{fig:algorithm}{{1}{6}{The overall proposed algorithm.\relax }{figure.caption.1}{}}
\newlabel{fig:algorithm@cref}{{[figure][1][]1}{[1][6][]6}}
\newlabel{sec:Results}{{3}{6}{Results\label {sec:Results}}{section.3}{}}
\newlabel{sec:Results@cref}{{[section][3][]3}{[1][6][]6}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{6}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Classification datasets }{6}{subsection.3.1}\protected@file@percent }
\citation{australian}
\citation{balance}
\citation{cleveland1,cleveland2}
\citation{dermatology}
\citation{ecoli}
\citation{heart}
\citation{housevotes}
\citation{liver}
\citation{parkinsons}
\citation{pima}
\citation{popfailures}
\citation{regions}
\citation{saheart}
\citation{segment}
\citation{sonar}
\citation{wdbc}
\citation{wine1,wine2}
\citation{eeg}
\citation{zoo}
\citation{airfoil}
\citation{Stat}
\citation{housing}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Regression datasets }{7}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Experimental results}{7}{subsection.3.3}\protected@file@percent }
\citation{Powell}
\citation{ipso}
\citation{doublepop}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Values for the experimental parameters.\relax }}{8}{table.caption.2}\protected@file@percent }
\newlabel{tab:settings}{{1}{8}{Values for the experimental parameters.\relax }{table.caption.2}{}}
\newlabel{tab:settings@cref}{{[table][1][]1}{[1][8][]8}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Experimental results using a series of optimization methods for the classification datasets. Numbers in cells denote average classification error as measured on the test set. The bold notation is used to identify the method with the lowest average classification error.\relax }}{9}{table.caption.3}\protected@file@percent }
\newlabel{tab:expClass}{{2}{9}{Experimental results using a series of optimization methods for the classification datasets. Numbers in cells denote average classification error as measured on the test set. The bold notation is used to identify the method with the lowest average classification error.\relax }{table.caption.3}{}}
\newlabel{tab:expClass@cref}{{[table][2][]2}{[1][8][]9}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Experimental results for different optimization methods on a series of regression datasets. Numbers in cells denote average regression error as measure on the test set. The bold notation is used to express the method with the lowest average regression error. \relax }}{10}{table.caption.4}\protected@file@percent }
\newlabel{tab:expRegression}{{3}{10}{Experimental results for different optimization methods on a series of regression datasets. Numbers in cells denote average regression error as measure on the test set. The bold notation is used to express the method with the lowest average regression error. \relax }{table.caption.4}{}}
\newlabel{tab:expRegression@cref}{{[table][3][]3}{[1][9][]10}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Statistical comparison of the used optimization methods for the classification datasets.\relax }}{10}{figure.caption.5}\protected@file@percent }
\newlabel{fig:statClass}{{2}{10}{Statistical comparison of the used optimization methods for the classification datasets.\relax }{figure.caption.5}{}}
\newlabel{fig:statClass@cref}{{[figure][2][]2}{[1][10][]10}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Time comparison of the average execution time for the classification datasets.\relax }}{11}{figure.caption.6}\protected@file@percent }
\newlabel{fig:timeComparison}{{3}{11}{Time comparison of the average execution time for the classification datasets.\relax }{figure.caption.6}{}}
\newlabel{fig:timeComparison@cref}{{[figure][3][]3}{[1][10][]11}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Experimental results using different values for the critical parameter $F$. The experiments were executed on the classification datasets. The numbers in cells denote average classification error, as measured on the test set.\relax }}{12}{table.caption.7}\protected@file@percent }
\newlabel{tab:experF}{{4}{12}{Experimental results using different values for the critical parameter $F$. The experiments were executed on the classification datasets. The numbers in cells denote average classification error, as measured on the test set.\relax }{table.caption.7}{}}
\newlabel{tab:experF@cref}{{[table][4][]4}{[1][11][]12}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Experiments using the parameter $N_{R}$ of the proposed algorithm. The experiments were performed by applying the proposed method on the used classification datasets. The numbers in cells stand for the average classification error, as measured on the corresponding test set.\relax }}{13}{table.caption.8}\protected@file@percent }
\newlabel{tab:experNR}{{5}{13}{Experiments using the parameter $N_{R}$ of the proposed algorithm. The experiments were performed by applying the proposed method on the used classification datasets. The numbers in cells stand for the average classification error, as measured on the corresponding test set.\relax }{table.caption.8}{}}
\newlabel{tab:experNR@cref}{{[table][5][]5}{[1][12][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Statistical comparison for the results obtained by the proposed method as applied on the classification datasets, using different values of the parameter $N_{R}$.\relax }}{14}{figure.caption.9}\protected@file@percent }
\newlabel{fig:statNR}{{4}{14}{Statistical comparison for the results obtained by the proposed method as applied on the classification datasets, using different values of the parameter $N_{R}$.\relax }{figure.caption.9}{}}
\newlabel{fig:statNR@cref}{{[figure][4][]4}{[1][13][]14}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Experiments using the proposed method on the classification datasets for various values of the parameter $N_{I}$. Numbers in cells denote average classification error as measured on the test set.\relax }}{15}{table.caption.10}\protected@file@percent }
\newlabel{tab:experNI}{{6}{15}{Experiments using the proposed method on the classification datasets for various values of the parameter $N_{I}$. Numbers in cells denote average classification error as measured on the test set.\relax }{table.caption.10}{}}
\newlabel{tab:experNI@cref}{{[table][6][]6}{[1][14][]15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Statistical comparison for the results obtained by the proposed method as applied on the classification datasets, using different values of the parameter $L_{I}$.\relax }}{16}{figure.caption.11}\protected@file@percent }
\newlabel{fig:statNI}{{5}{16}{Statistical comparison for the results obtained by the proposed method as applied on the classification datasets, using different values of the parameter $L_{I}$.\relax }{figure.caption.11}{}}
\newlabel{fig:statNI@cref}{{[figure][5][]5}{[1][15][]16}}
\newlabel{sec:Conclusions}{{4}{16}{Conclusions\label {sec:Conclusions}}{section.4}{}}
\newlabel{sec:Conclusions@cref}{{[section][4][]4}{[1][16][]16}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusions}{16}{section.4}\protected@file@percent }
\citation{psa}
\citation{rbf1}
\bibcite{nn1}{{1}{}{{}}{{}}}
\bibcite{nn2}{{2}{}{{}}{{}}}
\bibcite{nnphysics1}{{3}{}{{}}{{}}}
\bibcite{nnphysics2}{{4}{}{{}}{{}}}
\bibcite{nnphysics3}{{5}{}{{}}{{}}}
\bibcite{nnchem1}{{6}{}{{}}{{}}}
\bibcite{nnchem2}{{7}{}{{}}{{}}}
\bibcite{nnchem3}{{8}{}{{}}{{}}}
\bibcite{nnecon1}{{9}{}{{}}{{}}}
\bibcite{nnecon2}{{10}{}{{}}{{}}}
\bibcite{nncecon3}{{11}{}{{}}{{}}}
\bibcite{nnmed1}{{12}{}{{}}{{}}}
\bibcite{nnmed2}{{13}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}References}{17}{section.5}\protected@file@percent }
\bibcite{nn_flood}{{14}{}{{}}{{}}}
\bibcite{nn_solar}{{15}{}{{}}{{}}}
\bibcite{nn_agro}{{16}{}{{}}{{}}}
\bibcite{nn_wireless}{{17}{}{{}}{{}}}
\bibcite{nn_mech1}{{18}{}{{}}{{}}}
\bibcite{nnc}{{19}{}{{}}{{}}}
\bibcite{activation_spline}{{20}{}{{}}{{}}}
\bibcite{activation_trained}{{21}{}{{}}{{}}}
\bibcite{activation_review}{{22}{}{{}}{{}}}
\bibcite{bpnn}{{23}{}{{}}{{}}}
\bibcite{bpnn2}{{24}{}{{}}{{}}}
\bibcite{nn_leve}{{25}{}{{}}{{}}}
\bibcite{rpropnn}{{26}{}{{}}{{}}}
\bibcite{rpropnn3}{{27}{}{{}}{{}}}
\bibcite{rpropnn2}{{28}{}{{}}{{}}}
\bibcite{quasinn}{{29}{}{{}}{{}}}
\bibcite{quasinn2}{{30}{}{{}}{{}}}
\bibcite{psonn}{{31}{}{{}}{{}}}
\bibcite{psonn2}{{32}{}{{}}{{}}}
\bibcite{nn_de}{{33}{}{{}}{{}}}
\bibcite{nn_survey}{{34}{}{{}}{{}}}
\bibcite{nnhybrid1}{{35}{}{{}}{{}}}
\bibcite{nnhybrid2}{{36}{}{{}}{{}}}
\bibcite{csmethod}{{37}{}{{}}{{}}}
\bibcite{nninit1}{{38}{}{{}}{{}}}
\bibcite{weight_init2}{{39}{}{{}}{{}}}
\bibcite{weight_init3}{{40}{}{{}}{{}}}
\bibcite{nninitreview}{{41}{}{{}}{{}}}
\bibcite{nn_gpu1}{{42}{}{{}}{{}}}
\bibcite{nn_gpu2}{{43}{}{{}}{{}}}
\bibcite{nn_gpu3}{{44}{}{{}}{{}}}
\bibcite{nn_gpu_review}{{45}{}{{}}{{}}}
\bibcite{Holland}{{46}{}{{}}{{}}}
\bibcite{Stender}{{47}{}{{}}{{}}}
\bibcite{Goldberg}{{48}{}{{}}{{}}}
\bibcite{Michaelewicz}{{49}{}{{}}{{}}}
\bibcite{ga_problem1}{{50}{}{{}}{{}}}
\bibcite{ga_problem2}{{51}{}{{}}{{}}}
\bibcite{ga_problem3}{{52}{}{{}}{{}}}
\bibcite{ga_problem4}{{53}{}{{}}{{}}}
\bibcite{ga_problem5}{{54}{}{{}}{{}}}
\bibcite{ga_nn1}{{55}{}{{}}{{}}}
\bibcite{ga_nn2}{{56}{}{{}}{{}}}
\bibcite{ga_nn3}{{57}{}{{}}{{}}}
\bibcite{ga_nn4}{{58}{}{{}}{{}}}
\bibcite{ga_nn5}{{59}{}{{}}{{}}}
\bibcite{siman_main}{{60}{}{{}}{{}}}
\bibcite{siman_problem1}{{61}{}{{}}{{}}}
\bibcite{siman_problem2}{{62}{}{{}}{{}}}
\bibcite{siman_problem3}{{63}{}{{}}{{}}}
\bibcite{ga_sa1}{{64}{}{{}}{{}}}
\bibcite{ga_sa2}{{65}{}{{}}{{}}}
\bibcite{ga_sa3}{{66}{}{{}}{{}}}
\bibcite{ga_sa4}{{67}{}{{}}{{}}}
\bibcite{ga_sa5}{{68}{}{{}}{{}}}
\bibcite{ga_drug}{{69}{}{{}}{{}}}
\bibcite{ga_gear}{{70}{}{{}}{{}}}
\bibcite{ga_forecasting}{{71}{}{{}}{{}}}
\bibcite{kaelo}{{72}{}{{}}{{}}}
\bibcite{Powell}{{73}{}{{}}{{}}}
\bibcite{UCL}{{74}{}{{}}{{}}}
\bibcite{Keel}{{75}{}{{}}{{}}}
\bibcite{appendicitis}{{76}{}{{}}{{}}}
\bibcite{australian}{{77}{}{{}}{{}}}
\bibcite{balance}{{78}{}{{}}{{}}}
\bibcite{cleveland1}{{79}{}{{}}{{}}}
\bibcite{cleveland2}{{80}{}{{}}{{}}}
\bibcite{dermatology}{{81}{}{{}}{{}}}
\bibcite{ecoli}{{82}{}{{}}{{}}}
\bibcite{heart}{{83}{}{{}}{{}}}
\bibcite{housevotes}{{84}{}{{}}{{}}}
\bibcite{liver}{{85}{}{{}}{{}}}
\bibcite{parkinsons}{{86}{}{{}}{{}}}
\bibcite{pima}{{87}{}{{}}{{}}}
\bibcite{popfailures}{{88}{}{{}}{{}}}
\bibcite{regions}{{89}{}{{}}{{}}}
\bibcite{saheart}{{90}{}{{}}{{}}}
\bibcite{segment}{{91}{}{{}}{{}}}
\bibcite{sonar}{{92}{}{{}}{{}}}
\bibcite{wdbc}{{93}{}{{}}{{}}}
\bibcite{wine1}{{94}{}{{}}{{}}}
\bibcite{wine2}{{95}{}{{}}{{}}}
\bibcite{eeg}{{96}{}{{}}{{}}}
\bibcite{zoo}{{97}{}{{}}{{}}}
\bibcite{airfoil}{{98}{}{{}}{{}}}
\bibcite{Stat}{{99}{}{{}}{{}}}
\bibcite{housing}{{100}{}{{}}{{}}}
\bibcite{ipso}{{101}{}{{}}{{}}}
\bibcite{doublepop}{{102}{}{{}}{{}}}
\bibcite{psa}{{103}{}{{}}{{}}}
\bibcite{rbf1}{{104}{}{{}}{{}}}
\newlabel{LastPage}{{}{21}{}{page.21}{}}
\xdef\lastpage@lastpage{21}
\xdef\lastpage@lastpageHy{21}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\expandafter\ifx\csname c@page@totc\endcsname\relax\newcounter{page@totc}\fi\setcounter{page@totc}{22}
\gdef \@abspage@last{21}
