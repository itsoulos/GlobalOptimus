\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{Definitions/mdpi}
\citation{nn1,nn2}
\citation{nnc}
\newmarginnote{note.1.1}{{1}{10945661sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{eq:eq1}{{1}{1}{Introduction}{equation.1.1}{}}
\newlabel{eq:eq1@cref}{{[equation][1][]1}{[1][1][]1}}
\citation{activation_spline}
\citation{activation_trained}
\citation{activation_review}
\citation{nn_image}
\citation{nn_timeseries}
\citation{nn_credit}
\citation{nnphysics1,nnphysics2}
\citation{nn_flood}
\citation{nn_solar}
\citation{nn_agro}
\citation{nn_wireless}
\citation{nnmed1,nnmed2}
\citation{nn_mech1}
\citation{bpnn2}
\citation{rpropnn-1,rpropnn-2}
\citation{nn_adam}
\citation{geneticnn1,geneticnn2}
\citation{psonn}
\citation{nn_siman}
\citation{weight_de1}
\citation{nn_abc}
\citation{nn_wolf}
\citation{tabunn}
\citation{nn_hybrid}
\citation{nn_cascade}
\citation{nn_gpu1,nn_gpu2}
\citation{aimeta1,aimeta2}
\citation{nnsharing1,nnsharing2}
\citation{nnprunning1,nnprunning2}
\citation{nnearly1,nnearly2}
\citation{nndecay1,nndecay2}
\citation{nn_arch1,nn_arch2}
\citation{nn_arch3}
\citation{nn_ereinf}
\newlabel{eq:nn}{{2}{2}{Introduction}{equation.1.2}{}}
\newlabel{eq:nn@cref}{{[equation][2][]2}{[1][2][]2}}
\newlabel{eq:sig}{{3}{2}{Introduction}{equation.1.3}{}}
\newlabel{eq:sig@cref}{{[equation][3][]3}{[1][2][]2}}
\newlabel{eq:tanh}{{4}{2}{Introduction}{equation.1.4}{}}
\newlabel{eq:tanh@cref}{{[equation][4][]4}{[1][2][]2}}
\citation{naiveInit}
\citation{glorotInit}
\citation{heInit}
\citation{siman1}
\citation{sa_resource}
\citation{sa_portfolio}
\citation{sa_solar}
\citation{sa_biology}
\citation{sa_multi}
\citation{sa_timetable}
\citation{sa_tsp}
\citation{sa_cooling1,sa_cooling2}
\newlabel{sec:Materials-and-Methods}{{2}{3}{Materials and Methods\label {sec:Materials-and-Methods}}{section.2}{}}
\newlabel{sec:Materials-and-Methods@cref}{{[section][2][]2}{[1][3][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Materials and Methods}{3}{section.2}\protected@file@percent }
\citation{nnt_bound}
\newlabel{subsec:The-proposed-Simulated}{{2.1}{4}{The proposed Simulated Annealing variant \label {subsec:The-proposed-Simulated}}{subsection.2.1}{}}
\newlabel{subsec:The-proposed-Simulated@cref}{{[subsection][1][2]2.1}{[1][3][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The proposed Simulated Annealing variant }{4}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Plot of the sigmoid function $\sigma (x)$ in the range $[-5,5]$.}}{4}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:plotsigma}{{1}{4}{Plot of the sigmoid function $\sigma (x)$ in the range $[-5,5]$}{figure.caption.1}{}}
\newlabel{fig:plotsigma@cref}{{[figure][1][]1}{[1][4][]4}}
\newlabel{alg:CalculationBound}{{1}{5}{The following algorithm is used to calculate the quantity for neural network $N(x,w)$ and a provided input $a$}{algorithm.1}{}}
\newlabel{alg:CalculationBound@cref}{{[algorithm][1][]1}{[1][5][]5}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces The following algorithm is used to calculate the quantity for neural network $N(x,w)$ and a provided input $a$.}}{5}{algorithm.1}\protected@file@percent }
\newlabel{alg:simanVariant}{{2}{6}{The main steps of the proposed Simulated Annealing variant}{algorithm.2}{}}
\newlabel{alg:simanVariant@cref}{{[algorithm][2][]2}{[1][5][]6}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces The main steps of the proposed Simulated Annealing variant.}}{6}{algorithm.2}\protected@file@percent }
\newlabel{enu:forFitness}{{5}{6}{The main steps of the proposed Simulated Annealing variant}{Item.14}{}}
\newlabel{enu:forFitness@cref}{{[enumi][5][]5}{[1][5][]6}}
\newlabel{alg:fitness}{{3}{6}{The algorithm below is used to calculate the function value for a specified interval of parameters}{algorithm.3}{}}
\newlabel{alg:fitness@cref}{{[algorithm][3][]3}{[1][6][]6}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces The algorithm below is used to calculate the function value for a specified interval of parameters.}}{6}{algorithm.3}\protected@file@percent }
\newlabel{alg:sampling}{{4}{7}{The following procedure is used to produce new random intervals for the bounds of the parameters of the neural network}{algorithm.4}{}}
\newlabel{alg:sampling@cref}{{[algorithm][4][]4}{[1][6][]7}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces The following procedure is used to produce new random intervals for the bounds of the parameters of the neural network.}}{7}{algorithm.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}The final training method}{7}{subsection.2.2}\protected@file@percent }
\citation{kaelo}
\citation{powell}
\citation{uci}
\citation{Keel}
\citation{appendicitis}
\citation{alcohol}
\citation{australian}
\citation{balance}
\citation{cleveland1,cleveland2}
\citation{dermatology}
\newlabel{eq:crossover_ali}{{6}{8}{The final training method}{equation.2.6}{}}
\newlabel{eq:crossover_ali@cref}{{[enumii][2][3]3b}{[1][8][]8}}
\newlabel{eq:ali_mutation}{{7}{8}{The final training method}{equation.2.7}{}}
\newlabel{eq:ali_mutation@cref}{{[equation][7][]7}{[1][8][]8}}
\newlabel{eq:delta_equation}{{8}{8}{The final training method}{equation.2.8}{}}
\newlabel{eq:delta_equation@cref}{{[equation][8][]8}{[1][8][]8}}
\newlabel{sec:Results}{{3}{8}{Results\label {sec:Results}}{section.3}{}}
\newlabel{sec:Results@cref}{{[section][3][]3}{[1][8][]8}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{8}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Experimental datasets}{8}{subsection.3.1}\protected@file@percent }
\citation{ecoli}
\citation{hayes-roth}
\citation{heart}
\citation{housevotes}
\citation{ion1,ion2}
\citation{liver,liver1}
\citation{lymography}
\citation{mammographic}
\citation{parkinsons1,parkinsons2}
\citation{pima}
\citation{popfailures}
\citation{regions2}
\citation{saheart}
\citation{segment}
\citation{student}
\citation{transfusion}
\citation{wdbc1,wdbc2}
\citation{wine1,wine2}
\citation{eeg1,eeg2}
\citation{zoo}
\citation{abalone}
\citation{airfoil}
\citation{concrete}
\citation{friedman}
\citation{housing}
\citation{optimus}
\citation{nn_adam}
\citation{rbf1,rbf2}
\citation{neat}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Experimental results}{10}{subsection.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The values for every experimental parameter.}}{10}{table.caption.2}\protected@file@percent }
\newlabel{tab:settings}{{1}{10}{The values for every experimental parameter}{table.caption.2}{}}
\newlabel{tab:settings@cref}{{[table][1][]1}{[1][10][]10}}
\citation{prune}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Experimental results on the classification datasets using the series of the machine learning methods. Numbers in cells represent average classification error as measured on the corresponding test set.}}{12}{table.caption.3}\protected@file@percent }
\newlabel{tab:expClass}{{2}{12}{Experimental results on the classification datasets using the series of the machine learning methods. Numbers in cells represent average classification error as measured on the corresponding test set}{table.caption.3}{}}
\newlabel{tab:expClass@cref}{{[table][2][]2}{[1][11][]12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Statistical significance levels (Friedman and post-hoc) for classification experiments across learning models}}{13}{figure.caption.4}\protected@file@percent }
\newlabel{fig:stat_class_methods}{{2}{13}{Statistical significance levels (Friedman and post-hoc) for classification experiments across learning models}{figure.caption.4}{}}
\newlabel{fig:stat_class_methods@cref}{{[figure][2][]2}{[1][12][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Genetic algorithm versus the proposed method across network size.}}{13}{figure.caption.5}\protected@file@percent }
\newlabel{fig:networkSize}{{3}{13}{Genetic algorithm versus the proposed method across network size}{figure.caption.5}{}}
\newlabel{fig:networkSize@cref}{{[figure][3][]3}{[1][13][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The estimated intervals for the neural network parameters from the proposed Simulated Annealing for three datasets.}}{14}{figure.caption.6}\protected@file@percent }
\newlabel{fig:The-estimated-intervals}{{4}{14}{The estimated intervals for the neural network parameters from the proposed Simulated Annealing for three datasets}{figure.caption.6}{}}
\newlabel{fig:The-estimated-intervals@cref}{{[figure][4][]4}{[1][14][]14}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Experimental results on the regression datasets using the list of the provided machine learning methods. Numbers in cells represent average regression error on each test set.}}{15}{table.caption.7}\protected@file@percent }
\newlabel{tab:expRegression}{{3}{15}{Experimental results on the regression datasets using the list of the provided machine learning methods. Numbers in cells represent average regression error on each test set}{table.caption.7}{}}
\newlabel{tab:expRegression@cref}{{[table][3][]3}{[1][15][]15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Statistical significance levels (Friedman and post-hoc) for regression experiments across learning models}}{16}{figure.caption.8}\protected@file@percent }
\newlabel{fig:stat_regre_methods}{{5}{16}{Statistical significance levels (Friedman and post-hoc) for regression experiments across learning models}{figure.caption.8}{}}
\newlabel{fig:stat_regre_methods@cref}{{[figure][5][]5}{[1][15][]16}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces An indicative comparison of the training process between the genetic algorithm and the proposed method for the MORTGAGE dataset.}}{16}{figure.caption.9}\protected@file@percent }
\newlabel{fig:An-indicative-comparison}{{6}{16}{An indicative comparison of the training process between the genetic algorithm and the proposed method for the MORTGAGE dataset}{figure.caption.9}{}}
\newlabel{fig:An-indicative-comparison@cref}{{[figure][6][]6}{[1][16][]16}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Average execution time comparison between the genetic algorithm and the proposed method for different number of weights for the neural network.}}{17}{figure.caption.10}\protected@file@percent }
\newlabel{fig:time}{{7}{17}{Average execution time comparison between the genetic algorithm and the proposed method for different number of weights for the neural network}{figure.caption.10}{}}
\newlabel{fig:time@cref}{{[figure][7][]7}{[1][17][]17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Experiments with the perturbation parameter $p_{c}$ }{17}{subsection.3.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Experimental results using the proposed method and a variety values for the perturbation factor $p_{c}$.}}{18}{table.caption.11}\protected@file@percent }
\newlabel{tab:expClassPC}{{4}{18}{Experimental results using the proposed method and a variety values for the perturbation factor $p_{c}$}{table.caption.11}{}}
\newlabel{tab:expClassPC@cref}{{[table][4][]4}{[1][18][]18}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Statistical comparison of $p_{c}$ settings for the proposed model on classification datasets}}{19}{figure.caption.12}\protected@file@percent }
\newlabel{fig:stat_class_pc}{{8}{19}{Statistical comparison of $p_{c}$ settings for the proposed model on classification datasets}{figure.caption.12}{}}
\newlabel{fig:stat_class_pc@cref}{{[figure][8][]8}{[1][18][]19}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Experimental results on the regression datasets using the proposed method and a series of values for the perturbation factor $p_{c}$.}}{20}{table.caption.13}\protected@file@percent }
\newlabel{tab:expRegressionPc}{{5}{20}{Experimental results on the regression datasets using the proposed method and a series of values for the perturbation factor $p_{c}$}{table.caption.13}{}}
\newlabel{tab:expRegressionPc@cref}{{[table][5][]5}{[1][19][]20}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Statistical comparison of $p_{c}$ settings for the proposed model on regression datasets}}{20}{figure.caption.14}\protected@file@percent }
\newlabel{fig:stat_regree_pc}{{9}{20}{Statistical comparison of $p_{c}$ settings for the proposed model on regression datasets}{figure.caption.14}{}}
\newlabel{fig:stat_regree_pc@cref}{{[figure][9][]9}{[1][20][]20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Experiments with the weight parameter $I_{w}$}{21}{subsection.3.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Experimental results on the classification dataset using the proposed method and different values for the weight parameter $I_{w}$.}}{22}{table.caption.15}\protected@file@percent }
\newlabel{tab:expClassIw}{{6}{22}{Experimental results on the classification dataset using the proposed method and different values for the weight parameter $I_{w}$}{table.caption.15}{}}
\newlabel{tab:expClassIw@cref}{{[table][6][]6}{[1][21][]22}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Statistical comparison of $I_{w}$ settings for the proposed model on classification datasets}}{23}{figure.caption.16}\protected@file@percent }
\newlabel{fig:stat_class_iw}{{10}{23}{Statistical comparison of $I_{w}$ settings for the proposed model on classification datasets}{figure.caption.16}{}}
\newlabel{fig:stat_class_iw@cref}{{[figure][10][]10}{[1][22][]23}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Experimental results with the application of the proposed method to the regression datasets, using a variety of values for the weight parameter $I_{w}$ .}}{24}{table.caption.17}\protected@file@percent }
\newlabel{tab:expRegressionIw}{{7}{24}{Experimental results with the application of the proposed method to the regression datasets, using a variety of values for the weight parameter $I_{w}$ }{table.caption.17}{}}
\newlabel{tab:expRegressionIw@cref}{{[table][7][]7}{[1][23][]24}}
\citation{initXavier}
\citation{initXE}
\citation{initLECUN}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Statistical comparison of $I_{w}$ settings for the proposed model on regression datasets}}{25}{figure.caption.18}\protected@file@percent }
\newlabel{fig:stat_regre_iw}{{11}{25}{Statistical comparison of $I_{w}$ settings for the proposed model on regression datasets}{figure.caption.18}{}}
\newlabel{fig:stat_regre_iw@cref}{{[figure][11][]11}{[1][24][]25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Experiments with initialization methods}{25}{subsection.3.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Experimental results on the classification datasets using the genetic algorithm as the training method and series of initialization methods.}}{26}{table.caption.19}\protected@file@percent }
\newlabel{tab:expClassInit}{{8}{26}{Experimental results on the classification datasets using the genetic algorithm as the training method and series of initialization methods}{table.caption.19}{}}
\newlabel{tab:expClassInit@cref}{{[table][8][]8}{[1][25][]26}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Experimental results on the regression datasets using the genetic algorithm as the training method of the neural network and a series of initialization techniques.}}{27}{table.caption.20}\protected@file@percent }
\newlabel{tab:expRegressionInit}{{9}{27}{Experimental results on the regression datasets using the genetic algorithm as the training method of the neural network and a series of initialization techniques}{table.caption.20}{}}
\newlabel{tab:expRegressionInit@cref}{{[table][9][]9}{[1][27][]27}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Statistical comparison on the results performed on the classification datasets using different initialization methods.}}{28}{figure.caption.21}\protected@file@percent }
\newlabel{fig:statClassInit}{{12}{28}{Statistical comparison on the results performed on the classification datasets using different initialization methods}{figure.caption.21}{}}
\newlabel{fig:statClassInit@cref}{{[figure][12][]12}{[1][27][]28}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Statistical comparison for the experiments performed on the regression datasets using different initialization methods.}}{29}{figure.caption.22}\protected@file@percent }
\newlabel{fig:statRegressionInit}{{13}{29}{Statistical comparison for the experiments performed on the regression datasets using different initialization methods}{figure.caption.22}{}}
\newlabel{fig:statRegressionInit@cref}{{[figure][13][]13}{[1][28][]29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Experiments with the cooling strategy}{29}{subsection.3.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Experimental results on the classification datasets using the proposed method and a series of cooling strategies. }}{30}{table.caption.23}\protected@file@percent }
\newlabel{tab:expClassCool}{{10}{30}{Experimental results on the classification datasets using the proposed method and a series of cooling strategies}{table.caption.23}{}}
\newlabel{tab:expClassCool@cref}{{[table][10][]10}{[1][29][]30}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Statistical comparison for the obtained results on the classification datasets using the proposed method and a series of cooling strategies.}}{31}{figure.caption.24}\protected@file@percent }
\newlabel{fig:statClassCooling}{{14}{31}{Statistical comparison for the obtained results on the classification datasets using the proposed method and a series of cooling strategies}{figure.caption.24}{}}
\newlabel{fig:statClassCooling@cref}{{[figure][14][]14}{[1][30][]31}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Experimental results on the regression datasets using the proposed method and a series of cooling strategies .}}{32}{table.caption.25}\protected@file@percent }
\newlabel{tab:expRegressionCool}{{11}{32}{Experimental results on the regression datasets using the proposed method and a series of cooling strategies }{table.caption.25}{}}
\newlabel{tab:expRegressionCool@cref}{{[table][11][]11}{[1][31][]32}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Statistical comparison for the obtained results on the regression datasets using the proposed method and a series of cooling strategies.}}{32}{figure.caption.26}\protected@file@percent }
\newlabel{fig:statRegressionCooling}{{15}{32}{Statistical comparison for the obtained results on the regression datasets using the proposed method and a series of cooling strategies}{figure.caption.26}{}}
\newlabel{fig:statRegressionCooling@cref}{{[figure][15][]15}{[1][31][]32}}
\newlabel{sec:Conclusions}{{4}{32}{Conclusions\label {sec:Conclusions}}{section.4}{}}
\newlabel{sec:Conclusions@cref}{{[section][4][]4}{[1][32][]32}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusions}{32}{section.4}\protected@file@percent }
\citation{psa1,psa2}
\bibcite{nn1}{{1}{year}{{}}{{}}}
\bibcite{nn2}{{2}{}{{}}{{}}}
\bibcite{nnc}{{3}{}{{}}{{}}}
\bibcite{activation_spline}{{4}{}{{}}{{}}}
\bibcite{activation_trained}{{5}{}{{}}{{}}}
\bibcite{activation_review}{{6}{}{{}}{{}}}
\bibcite{nn_image}{{7}{year}{{}}{{}}}
\bibcite{nn_timeseries}{{8}{}{{}}{{}}}
\bibcite{nn_credit}{{9}{}{{}}{{}}}
\bibcite{nnphysics1}{{10}{}{{}}{{}}}
\bibcite{nnphysics2}{{11}{}{{}}{{}}}
\bibcite{nn_flood}{{12}{}{{}}{{}}}
\bibcite{nn_solar}{{13}{}{{}}{{}}}
\bibcite{nn_agro}{{14}{}{{}}{{}}}
\bibcite{nn_wireless}{{15}{}{{}}{{}}}
\bibcite{nnmed1}{{16}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}References}{34}{section.5}\protected@file@percent }
\bibcite{nnmed2}{{17}{}{{}}{{}}}
\bibcite{nn_mech1}{{18}{}{{}}{{}}}
\bibcite{bpnn2}{{19}{}{{}}{{}}}
\bibcite{rpropnn-1}{{20}{}{{}}{{}}}
\bibcite{rpropnn-2}{{21}{}{{}}{{}}}
\bibcite{nn_adam}{{22}{}{{}}{{}}}
\bibcite{geneticnn1}{{23}{}{{}}{{}}}
\bibcite{geneticnn2}{{24}{year}{{}}{{}}}
\bibcite{psonn}{{25}{}{{}}{{}}}
\bibcite{nn_siman}{{26}{}{{}}{{}}}
\bibcite{weight_de1}{{27}{}{{}}{{}}}
\bibcite{nn_abc}{{28}{}{{}}{{}}}
\bibcite{nn_wolf}{{29}{year}{{}}{{}}}
\bibcite{tabunn}{{30}{}{{}}{{}}}
\bibcite{nn_hybrid}{{31}{}{{}}{{}}}
\bibcite{nn_cascade}{{32}{}{{}}{{}}}
\bibcite{nn_gpu1}{{33}{}{{}}{{}}}
\bibcite{nn_gpu2}{{34}{}{{}}{{}}}
\bibcite{aimeta1}{{35}{2025}{{}}{{}}}
\bibcite{aimeta2}{{36}{2025}{{}}{{}}}
\bibcite{nnsharing1}{{37}{year}{{}}{{}}}
\bibcite{nnsharing2}{{38}{}{{}}{{}}}
\bibcite{nnprunning1}{{39}{}{{}}{{}}}
\bibcite{nnprunning2}{{40}{}{{}}{{}}}
\bibcite{nnearly1}{{41}{}{{}}{{}}}
\bibcite{nnearly2}{{42}{}{{}}{{}}}
\bibcite{nndecay1}{{43}{}{{}}{{}}}
\bibcite{nndecay2}{{44}{}{{}}{{}}}
\bibcite{nn_arch1}{{45}{}{{}}{{}}}
\bibcite{nn_arch2}{{46}{}{{}}{{}}}
\bibcite{nn_arch3}{{47}{}{{}}{{}}}
\bibcite{nn_ereinf}{{48}{2001}{{}}{{}}}
\bibcite{naiveInit}{{49}{}{{}}{{}}}
\bibcite{glorotInit}{{50}{}{{}}{{}}}
\bibcite{heInit}{{51}{}{{}}{{}}}
\bibcite{siman1}{{52}{2006}{{}}{{}}}
\bibcite{sa_resource}{{53}{2006}{{}}{{}}}
\bibcite{sa_portfolio}{{54}{2006}{{}}{{}}}
\bibcite{sa_solar}{{55}{2006}{{}}{{}}}
\bibcite{sa_biology}{{56}{2006}{{}}{{}}}
\bibcite{sa_multi}{{57}{2006}{{}}{{}}}
\bibcite{sa_timetable}{{58}{2006}{{}}{{}}}
\bibcite{sa_tsp}{{59}{2006}{{}}{{}}}
\bibcite{sa_cooling1}{{60}{2006}{{}}{{}}}
\bibcite{sa_cooling2}{{61}{2006}{{}}{{}}}
\bibcite{nnt_bound}{{62}{2006}{{}}{{}}}
\bibcite{powell}{{63}{year}{{}}{{}}}
\bibcite{kaelo}{{64}{}{{}}{{}}}
\bibcite{uci}{{65}{year}{{Author1}}{{}}}
\bibcite{Keel}{{66}{}{{}}{{}}}
\bibcite{appendicitis}{{67}{}{{}}{{}}}
\bibcite{alcohol}{{68}{2018}{{Tzimourta}}{{}}}
\bibcite{australian}{{69}{2018}{{Quinlan}}{{}}}
\bibcite{balance}{{70}{}{{}}{{}}}
\bibcite{cleveland1}{{71}{2004}{{}}{{}}}
\bibcite{cleveland2}{{72}{}{{}}{{}}}
\bibcite{dermatology}{{73}{1998}{{}}{{}}}
\bibcite{ecoli}{{74}{1996}{{}}{{}}}
\bibcite{hayes-roth}{{75}{1977}{{}}{{}}}
\bibcite{heart}{{76}{1997}{{}}{{}}}
\bibcite{housevotes}{{77}{2002}{{}}{{}}}
\bibcite{ion1}{{78}{2004}{{}}{{}}}
\bibcite{ion2}{{79}{}{{}}{{}}}
\bibcite{liver}{{80}{2002}{{}}{{}}}
\bibcite{liver1}{{81}{}{{}}{{}}}
\bibcite{lymography}{{82}{2002}{{}}{{}}}
\bibcite{mammographic}{{83}{2007}{{}}{{}}}
\bibcite{parkinsons1}{{84}{2007}{{}}{{}}}
\bibcite{parkinsons2}{{85}{}{{}}{{}}}
\bibcite{pima}{{86}{2007}{{}}{{}}}
\bibcite{popfailures}{{87}{2007}{{}}{{}}}
\bibcite{regions2}{{88}{2007}{{}}{{}}}
\bibcite{saheart}{{89}{2007}{{}}{{}}}
\bibcite{segment}{{90}{}{{}}{{}}}
\bibcite{student}{{91}{2007}{{}}{{}}}
\bibcite{transfusion}{{92}{2007}{{}}{{}}}
\bibcite{wdbc1}{{93}{2007}{{}}{{}}}
\bibcite{wdbc2}{{94}{2007}{{}}{{}}}
\bibcite{wine1}{{95}{2007}{{}}{{}}}
\bibcite{wine2}{{96}{}{{}}{{}}}
\bibcite{eeg1}{{97}{2007}{{}}{{}}}
\bibcite{eeg2}{{98}{}{{}}{{}}}
\bibcite{zoo}{{99}{2007}{{}}{{}}}
\bibcite{abalone}{{100}{2007}{{}}{{}}}
\bibcite{airfoil}{{101}{2007}{{}}{{}}}
\bibcite{concrete}{{102}{2007}{{}}{{}}}
\bibcite{friedman}{{103}{}{{}}{{}}}
\bibcite{housing}{{104}{2007}{{}}{{}}}
\bibcite{optimus}{{105}{2022}{{}}{{}}}
\bibcite{rbf1}{{106}{1991}{{}}{{}}}
\bibcite{rbf2}{{107}{}{{}}{{}}}
\bibcite{neat}{{108}{2002}{{}}{{}}}
\bibcite{prune}{{109}{2002}{{}}{{}}}
\bibcite{initXavier}{{110}{2000}{{}}{{}}}
\bibcite{initXE}{{111}{2000}{{}}{{}}}
\bibcite{initLECUN}{{112}{2000}{{}}{{}}}
\bibcite{psa1}{{113}{2015}{{}}{{}}}
\bibcite{psa2}{{114}{2015}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{LastPage}{{}{38}{}{page.38}{}}
\xdef\lastpage@lastpage{38}
\xdef\lastpage@lastpageHy{38}
\gdef \@abspage@last{38}
